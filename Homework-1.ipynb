{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-1) How would you define Machine Learning?\n",
    "\n",
    "Machine learning is the subfield of artificial intelligence that enables algorithms to learn from data and make predictions without being explicitly programmed.\n",
    "\n",
    "### Question-2) What are the differences between Supervised and Unsupervised Learning? Specify example 3 algorithms for each of these.\n",
    "\n",
    "In supervised learning, the algorithms are trained from a set of labeled data. Using the labeled data, these algorithms produce an output model that can predict labels for new unlabeled data points. However, in unsupervised learning, the algorithms learn from a set of unlabeled data. These algorithms find the hidden patterns and useful insights from the unlabelled dataset. \n",
    "\n",
    "Examples of algorithms in supervised learning: Linear regression, support vector machines, and decision trees.\n",
    "Examples of unsupervised learning include k-means clustering, hierarchical clustering, and kernel density estimation.\n",
    "\n",
    "### Question-3) What are the test and validation set, and why would you want to use them?\n",
    "\n",
    "In machine learning models the data is split into three sets:(1) Training set, (2) validation set, and (3) test set. The training set is used to train the models. The validation set is used to estimate prediction error for model selection. The test set is used exclusively to assess the performance at the end of the process and will never be used in the training process.\n",
    "\n",
    "In practice,  multiple models are trained with various hyperparameters on the training set. Each model is tested on the validation set and the one which performs the best is selected. After the model is decided, the model is trained on the data which consists of both the training and the validation set. Finally, the obtained model is tested on the test set to get an estimate of the generalization error.\n",
    "\n",
    "### Question-4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?\n",
    "\n",
    "According to [1], the main steps for preprocessing data are in the following:\n",
    "\n",
    "#### 1. Data cleaning: \n",
    "\n",
    "This step deals with missing values, noise, outliers, and duplicate or incorrect values.\n",
    "\n",
    "    a. Missing values: There are two methods to deal with the missing data:\n",
    "        * Eliminate the missing values from the original data.\n",
    "        * Filling the missing values with mean or median of the available data \n",
    "    \n",
    "    b. Noisy Data (outliers): a random error in an observed variable is termed as noise. There are three methods to \n",
    "    deal with noisy data:\n",
    "        * In binning, the original data are divided into bins, and then they are replaced by a general value calculated for\n",
    "        that bin.\n",
    "        * In clustering, the data are grouped in clusters and then the outliers are detected and removed. \n",
    "        * In regression, the data are fitted to a specified (often linear) function.\n",
    "    \n",
    "    c. Inconsistent Data: The data may consist of duplicates or inconsistent data (which consists of contradictory values) due to several reasons. The duplicates should be removed. However, the decision on the inconsistent data should be taken considering the domain knowledge.\n",
    "    \n",
    "#### 2. Data integration: \n",
    "\n",
    "The raw data can come from multiple various datasets. This step reorganizes the various raw datasets into a single dataset that contains all the information required.\n",
    "\n",
    "#### 3. Data transformation:\n",
    "\n",
    "This step converts the data into an appropriate format for the machine-learning method to learn from. It involves the following:\n",
    "\n",
    "    a. Normalisation  \n",
    "        * Each feature in the data is scaled between a smaller range i.e. [0,1] or [-1,1]. - (Linear scaling) \n",
    "        * The data is scaled by using mean and standard deviation. - (Standardization)\n",
    " \n",
    "    b. Aggregation of the data, For example, daily sales data may be aggregated to compute monthly and annual total sales. \n",
    "    \n",
    "    c. In Generalisation of the Data, For example, the values for numerical values of age data can be mapped into young, middle-aged, or senior.\n",
    "\n",
    "#### 4. Data reduction: \n",
    "\n",
    "This step removes redundant records and variables, as well as reorganizes the data without compromising the integrity of the original data. Methods for data reduction include the following:\n",
    "\n",
    "    a. Principal Component Analysis (PCA):\n",
    "    b. Independent Component Analysis (ICA):\n",
    "    c. Linear Discriminant Analysis (LDA):\n",
    "    d. t-distributed Stochastic Neighbor Embedding (t-SNE):\n",
    "\n",
    "\n",
    "We need to prepare our data since real-world data in general incomplete, noisy, and inconsistent. This leads to poor quality machine-learning models. To deal with this problem, data preprocessing provides methods to organize the data in a way that becomes suitable for the machine learning model and it also increases the accuracy and efficiency of a machine learning model.\n",
    "\n",
    "\n",
    "[1] Malley B., Ramazzotti D., Wu J.T. (2016) Data Pre-processing. In: Secondary Analysis of Electronic Health Records. Springer, Cham. https://doi.org/10.1007/978-3-319-43742-2_12\n",
    "\n",
    "### Question-5) How you can explore countionus and discrete variables? \n",
    "\n",
    "Discrete variables are variables that can only take a finite number of values. However, continuous variables can take an infinite number of values.\n",
    "\n",
    "To explore if a variable is continuous or discrete, it should be checked if the variable is countable or not. if it is countable it is a discrete variable otherwise it is a continuous variable. For example, the height of a person may be recorded as 172 cm. However, the actual height on the measuring tape might be 172.3cm which was rounded off to 172 cm. If one had a better measuring instrument, the height may have obtained 172.342 cm. But the real height of this person is a number with indefinitely many decimal places such as 172.342975328â€¦ cm. So, this variable is continuous.\n",
    "\n",
    "### Question-6) Analyse the plot given below. (What is the plot and variable type, check the distribution and make comment about how you can preproccess it.)\n",
    "\n",
    "The given plot is a histogram and it shows the petal width data on the X-axis and its proportion to something else (perhaps to petal length) on the Y-axis. The variable is continuous. The plot has two peaks that's why the distribution type is a bimodal distribution. For preprocessing, \n",
    "\n",
    "1. Check if there are any missing values. If there is, fill the missing values with the median value.\n",
    "2. Check if there is an outlier in the data. If there is, eliminate it (or them) using the standard deviation method.\n",
    "3. Apply normalization to the data to convert it to an appropriate format where the machine-learning method can learn from.\n",
    "4. Split the data into training data (70% of the original data) and test data (30% of the original data).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
